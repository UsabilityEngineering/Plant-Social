# Requirements Gathering

## Summary of Formative Feedback/Findings

From our heuristic evaluation, we found that the UI of our app had **consistency**, **freedom**, and **flexibility**. We noted that the general layout of our interface is solid and it was understandable to the user due to conventions placed by other social-type apps. From the critiques, we noted that there was a discrepancy in how our top search bar would take you somewhere different than the bottom search button, and that our general app **aesthetic** was clunky. These notes helped us in our revision of our prototype.

From our cognitive walkthrough, a participant took on the role of **Kayla** from the scenarios that we provided. As Kayla, the confusing flow of our search feature became more prominent, as the participant was confused on the layout of the search buttons and where they took you. This solidified our need to re-work how we did our search. 

Based on the feedback, we made a re-work of the search feature in preparation for our next step. 

## Protocol Tasks

### Task 1

We asked participants to assume the role of someone who just got a plant, but they didn't know the name of it. Their task was to use the app to search for information on the unknown plant. Our expected goal for the user would be to end up using the camera feature to identify the plant.

This task would show us the **learnability** of searching for a plant with no name. By not knowing the name, we'd hope to see them navigate to the camera feature.

### Task 2

Participants were given the scenario of having a unique plant that they wanted to share with others. Their task was to share this unique plant through the app. Our expected goal for the user would be to make a post by navigating through the camera, selecting/uploading a photo, and hitting "post".

We wanted to measure the **effectiveness** for this task and view the **error tolerance** to see how they navigated the menus to make a post.

### Task 3

Participants were told that they had just seen someone's plant through the app and they had an interest in obtaining it. The task would involve them completing their goal of obtaining it. Our expected goal is for the user to interact with a post, click a user's profile, and hit message to start up a chat with them.

We were mainly looking to see how **learnability** in home screen navigation and **error tolerance** when trying to find an interactable post.

### Task 4

For the final task, participants were given the scenario that they had just bought a new plant and wanted to find out more information on how to take care of it. This task is similar to the first one, except there is an unspoken assumption that the participant would know the plant name. Our expected goal for the user would be to use the search feature to obtain information on the plant.

We wanted to again measure the **learnability** and **effectiveness** for users interacting with the search feature.

After every task, we asked our participants to give us a rating from 1-5, where 1 is "Very Difficult" and 5 is "Very Easy", on how they found the task. This was so we could measure the overall **usefulness** and **satisfaction** our participants perceived for the tasks.

## Approach to Study

We opted for a **think-aloud** approach for our study so we could observe their thought processes and behaviors while navigating our app's interface. The approach allows us to get a more detailed examination of what exactly our users would be thinking while using the app. Our assessment would fall under summative as what we recorded would influence our changes to the final prototype. 

## Interpretation of Data Summary

Participants seemed to have an easy time completing tasks, for the most part. Only 2/5 participants failed the first task and 1/5 for the last. This might be due to our lack of explicitly saying that there was knowledge of the plant name beforehand. A participant did catch onto the fact that they did know the plant name for the task, so they went from the camera to the search feature, showcasing our good **error tolerance** as they could go from one feature to another with ease.

Through the behaviors noted, we noticed that our current design didn't have explicit mention that you could identify a plant through the camera, so some participants struggled to complete the first task as we wanted them to attempt to use the camera. Some participants went straight to the search and called it good, thus failing the task, and others would just not interact with the camera as they didn't think it'd identify a plant. 

When it came to explicitly making a post, the participants found this task the easiest, with a 100% completion rate. Everyone was able to navigate to the camera and make a post through there. We feel like this high success rate is in part due to our use of social media **conventions** of having a recognizable button bar at the bottom. Participants recognized this convention immediately and knew what to do.

We initially had a side-bar menu with filters. When these filters were selected, the posts on the feed would have more information such as the author, comments, and plant type. In hindsight, it doesn't make sense why you would have to go through a side bar menu to get more of this information, but it became clear to us to revise this as more participants noted this.

Aside from the failed tasks, most participants rated the tasks a 5 in difficulty, with some 4 ratings, and one 3 rating. We feel like there is high **learnability**, **effectiveness**, and **efficiency** due to the high completion rates / low difficulty.

For our recommendations, we would go ahead to make it more clear that the camera can identify plants by adding a camera icon to the search bar as an indicator that you can also use your camera to search for a plant. We'd also go ahead and revise how information is displayed when you initially click on search, as one participant noted that they were confused on what was going on.

Another change would be to revise how we display plant posts on the feed. Instead of having to interact with a side bar menu, the author/plant name/comments would be shown by default.

## Supplementary Materials

[Protocol](plant-social-protocol.pdf)

[Prototype](#)

[Data Spreadsheet](plant-social-data.pdf)
